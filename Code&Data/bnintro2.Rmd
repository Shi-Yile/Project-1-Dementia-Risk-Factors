---
title: 'Bayesian Networks: Intro 2'
author: "Sara Wade"
date: '2022-06-07'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#setwd("~/Documents/GitHub/SwDS_DementiaRisk/R")
library(tidyverse)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(bnlearn)
library(Rgraphviz)
```

## Fitting Bayesian Networks: Longitudinal Data

We extend our simple example to include longitudinal observations for patients and also added another variable representing drinking behavior in the last three months (last six months in wave one). Let's start with some simple data cleaning and wrangling steps: check out the [data wrangling cheat sheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) and other [cheat sheets](https://www.rstudio.com/resources/cheatsheets/) from RStudio. In particular, we will define a new variable representing visit: baseline, 1st follow-up, 2nd follow-up,.... Then, we pivot the dataset, so that for each individual, we have variables representing their age and cognitive score at each visit. In this case, cognitive score is based only on recall due to high missingness in follow-ups measurements of orientation and numeracy. 

```{r italy}
italy = data.frame(read.csv("italy_2.csv", header = TRUE))

# Extract variables of interest
italy <- italy %>%  dplyr::select(c(mergeid, wave, age, female, cogscore2, isced1997_r,br010_mod))

# Rename education, cogscore, drinking
italy <- italy %>% rename(education = isced1997_r)
italy <- italy %>% rename(cogscore = cogscore2)
italy <- italy %>% rename(drinking = br010_mod)

# Filter to individuals at least 60 at their last interview
ids_rm = (unique(italy$mergeid))[italy$age[cumsum(table(italy$mergeid))]>=60]
italy = italy[italy$mergeid %in% ids_rm,]

# Discretize cognitive scores based on quantiles.
italy$cogscore <- cut(italy$cogscore, breaks = c(-1,quantile(italy$cogscore, probs = c(.1,.4),na.rm=TRUE),20), ordered_result = TRUE, labels = c("severe", "mild", "normal"))

# Create a variable representing baseline visit, 1st followup, ....
t <-  italy %>% pivot_wider(id_cols = mergeid, names_from = wave, values_from = wave, 
                            names_sort = TRUE)
t <- cbind(t[,1],t(apply(t[,-1],1,function(x){x - min(x, na.rm=T)} )))
t <- pivot_longer(t, cols = !mergeid, names_to = "wave", values_to = "visit")
italy$visit = t$visit[is.finite(t$visit)] 

# Create a variable representing education at baseline (if missing impute with min value at follow-up) and merge last two levels of education
edu <-  italy %>% pivot_wider(id_cols = mergeid, names_from = visit, values_from = education)
edu1 <- edu[,2]
names(edu1) = "education"
# find the rows missing at baseline and no missing in all columns
ind_impute = is.na(edu1)&apply(edu[,-1], 1, function(x){sum(is.na(x))!=8})
edu1[ind_impute,1] <- apply(edu[ind_impute,-1], 1, min, na.rm = T)
edu1$education[edu1$education == 6] = 5

# Create a variable representing gender at baseline
female =  italy %>% pivot_wider(id_cols = mergeid, names_from = visit, values_from = female)
female = female[,2]

# Complete the dataset based on visit 
italy <- italy %>% complete(mergeid, visit)

# Impute missing age at follow-up visits and discretize age into age groups and 
age <- italy %>% pivot_wider(id_cols = mergeid, names_from = visit, values_from = age)
# If age is missing, we impute with the previous age + 2 years, since follow-up visits occur approx every 2 years
impute_age = function(x){
  for(i in 2:length(x)){
    if(is.na(x[i])){ x[i]=x[i-1]+2 }
  }
  return(matrix(x, nrow =1))
}
age[,-1] <- t(apply(age[,-1],1, impute_age ))
age <- age %>% pivot_longer(cols = 2:9, names_to = "visit", values_to = "age")
italy$age <- cut(age$age, breaks = c(44,seq(55,90,5),117), ordered_result = TRUE, 
                 right =FALSE)

# Change drinking into an ordered factor and combine some levels
italy$drinking[italy$drinking ==2 | italy$drinking ==3] =2
italy$drinking[italy$drinking ==4 | italy$drinking ==5] =3
italy$drinking[italy$drinking ==6 | italy$drinking ==7] =4
italy$drinking = factor(italy$drinking,order = T)

# Pivot wider, so rows correspond to individuals with additional variables for age, cognitive score, drinking at each follow-up visit
italy <- italy %>% pivot_wider(id_cols = c(mergeid), names_from = visit, values_from =
                                 c(age,cogscore,drinking))
italy$education = factor(pull(edu1, "education"),order = T)
italy$female = factor(pull(female, "0"))

# Drop columns for drinking at follow-up 5:7, no obses
italy = italy[,-grep('drinking', names(italy))[6:8]]

# Drop id
italy = italy[,-1]
italy = as.data.frame(italy)
head(italy)
```

### Structure Learning

To estimate the DAG, we start by creating our blacklist. Our blacklist includes all arrows pointing to our demographic variables, age and gender. Since education is considered to happen earlier in life, we blacklist all arrows pointing to education, except gender. We also blacklist all orderings of cognitive scores and drinking that violate the temporal dependence. Moreover, we only allow cognitive score to depend on the current age. 

```{r blacklist}
# Create blacklist
# No arrows pointing to gender
bl = matrix(cbind(names(italy)[-(grep('female', names(italy)))], "female"), ncol=2, 
            dimnames =list(NULL,c("from","to")))
# No arrows pointing to age
for (age in names(italy)[grep('age', names(italy))]){
  bl2 = matrix(cbind(names(italy)[-(grep(age, names(italy)))], age), ncol=2, 
            dimnames =list(NULL,c("from","to")))
  bl = rbind(bl, bl2)
}
# Only allow education to possibly depend on gender
bl2 = matrix(cbind(names(italy)[-c(grep("education", names(italy)), 
                                   grep("female", names(italy)) )], "education"), 
             ncol=2, dimnames =list(NULL,c("from","to")))
bl= rbind(bl, bl2)
# Black orderings of cogscore and drinking that violate temporal structure
bl2 = ordering2blacklist(names(italy)[grep('cogscore', names(italy))])
bl3 = ordering2blacklist(names(italy)[grep('drinking', names(italy))])
bl= rbind(bl, bl2, bl3)
# For each cogscore, we only want to consider the current age; don't allow cogscore today to influence drinking in the past six months; and future drinking to influence today's cogscore
bl2 = matrix(cbind(names(italy)[grep('cogscore', names(italy))][1:5], 
                   names(italy)[grep('drinking', names(italy))]), 
             ncol=2, dimnames =list(NULL,c("from","to")))
bl= rbind(bl, bl2)
for (i in 1:8){
  cog = names(italy)[grep('cog', names(italy))][i]
  bl2 = matrix(cbind(names(italy)[(grep('age', names(italy)))][-i], cog), ncol=2, 
            dimnames =list(NULL,c("from","to")))
  bl = rbind(bl, bl2)
  if (i <5){
      bl2 = matrix(cbind(names(italy)[(grep('drinking', names(italy)))][(i+1):5], cog), ncol=2, 
            dimnames =list(NULL,c("from","to")))
      bl = rbind(bl, bl2)
  }
}
```

We also create a set of arrows representing the basic temporal structural dependence. This will be included as our whitelist. 

```{r dag}
dag = empty.graph(nodes = names(italy))
arc.set = matrix(cbind(names(italy)[(grep('age', names(italy)))], 
                       names(italy)[(grep('cog',names(italy)))]), 
                 ncol=2, dimnames =list(NULL,c("from","to")))
arc.set2 = matrix(cbind(names(italy)[(grep('cog', names(italy)))][-8], 
                       names(italy)[(grep('cog',names(italy)))][-1]), 
                 ncol=2, dimnames =list(NULL,c("from","to")))
arc.set3 = matrix(cbind(names(italy)[(grep('drinking', names(italy)))][-5], 
                       names(italy)[(grep('drinking',names(italy)))][-1]), 
                 ncol=2, dimnames =list(NULL,c("from","to")))
arc.set = rbind(arc.set, arc.set2,arc.set3)
arcs(dag) = arc.set
graphviz.plot(dag)
```

Next, we fit the DAG. Here we use the IAMB algorithm with the mutual information test. However, we can also run with other algorithms and tests to check similarities/differences in the estimated graphs. We focus on constraint-based algorithms, due to high levels of missingness for some variables.

```{r const}
# Use incremental association Markov blanket to learn the DAG
italy.iamb =iamb(italy, blacklist = bl, whitelist = arc.set, test ='mi')
graphviz.plot(italy.iamb)
```

Let's check for some missing arrows with conditional independence tests. When the sample size is small, we can use the Monte Carlo permutation test; these will be slower to run but do not rely on asymptotic theory. When testing for dependence between ordinal variables, we use the Jonckheere-Terpstra trend test by setting `test=jt`.

```{r citests, warning=FALSE}
# Testing for conditional independence: gender
ci.test("cogscore_0", "female", c("age_0","education"), test = "mi", data = italy)
ci.test("cogscore_1", "female", c("age_1","cogscore_0"), test = "mi", data = italy)
ci.test("education", "female", data=italy,test="mi")
dag.italy = set.arc(italy.iamb, from = "female", to = "education")

# Testing for conditional independence: education
ci.test("cogscore_1", "education", c("age_1","cogscore_0"), test = "jt", data = italy)
dag.italy = set.arc(dag.italy, from = "education", to = "cogscore_1")
ci.test("cogscore_2", "education", c("age_2","cogscore_1"), test = "jt", data = italy)
dag.italy = set.arc(dag.italy, from = "education", to = "cogscore_2")
ci.test("cogscore_3", "education", c("age_3","cogscore_2"), test = "jt", data = italy)
dag.italy = set.arc(dag.italy, from = "education", to = "cogscore_3")
ci.test("cogscore_4", "education", c("age_4","cogscore_3"), test = "jt", data = italy)
dag.italy = set.arc(dag.italy, from = "education", to = "cogscore_4")
ci.test("cogscore_5", "education", c("age_5","cogscore_4"), test = "jt", data = italy)
dag.italy = set.arc(dag.italy, from = "education", to = "cogscore_5")
ci.test("cogscore_6", "education", c("age_6","cogscore_5"), test = "mc-jt", B=1000, data = italy)
dag.italy = set.arc(dag.italy, from = "education", to = "cogscore_6")
ci.test("cogscore_7", "education", c("age_7","cogscore_6"), test = "mc-jt", B=1000, data = italy)
dag.italy = set.arc(dag.italy, from = "education", to = "cogscore_7")

# Testing for conditional independence: drinking
ci.test("cogscore_0", "drinking_0", c("age_0","education"), test = "mc-jt", B=1000, data = italy)
ci.test("cogscore_1", "drinking_1", c("age_1","education","cogscore_0"), test = "mc-jt", B=1000,
        data = italy)
ci.test("cogscore_2", "drinking_2", c("age_2","education","cogscore_1"), test = "mc-jt", B=1000,
        data = italy)
ci.test("cogscore_3", "drinking_3", c("age_3","education","cogscore_2"), test = "mc-jt", B=1000,
        data = italy)
ci.test("cogscore_4", "drinking_4", c("age_4","education","cogscore_3"), test = "mc-jt", B=1000,
        data = italy)
# Interestingly, when we restrict to women the null hypothesis is rejected
ci.test("cogscore_0", "drinking_0", c("age_0","education"), test = "mc-jt", B=1000, data = italy[italy$female==1,])

graphviz.plot(dag.italy)
```

Interestingly, when we restrict to women the null hypothesis that baseline cognitive score and drinking are independent is rejected. Thus, it may be interesting to compare the DAG above, with that obtained only for men and women. 

### Parameter estimation

In the following, we simply fit with `method = bayes`. To avoid overfitting, we could use ordinal regression as in the first introduction file, with additional assumptions such as stationarity over time.

```{r fit}
italy.fit = bn.fit(dag.italy, data = italy, method = "bayes", iss = 10)
```

### Plotting and Predicting with evidence

```{r grain, message=FALSE}
# We will need the gRain package
library(gRain)
```

For an individual with missing follow-up data, we can plot the marginal distribution of each node conditioned on the data available. 

```{r plot_i2,fig.width = 9, fig.height = 8}
# Use the gRain package to set evidence (condition on an event)
junction = compile(as.grain(italy.fit))
jf = setEvidence(junction, names(italy)[!is.na(italy[2,])],
                 as.vector(apply(italy[2,!is.na(italy[2,])],2,paste)))

graphviz.chart(italy.fit, grid = TRUE, main = "Original BN")
graphviz.chart(as.bn.fit(jf,including.evidence = TRUE), grid = TRUE, 
               bar.col = c(rep("grey", 9), rep("black", dim(italy)[2]-11), rep("grey", 2)),
              strip.bg = c(rep("grey", 9), rep("transparent", dim(italy)[2]-11), rep("grey", 2)),
               main = "BN given observed values for individual 2")
```

We can also use the predict function to predict the cognitive score at the follow-up visits. 

```{r pred}
italy.pred = predict(italy.fit, data= italy[2,!is.na(italy[2,])], node = c("cogscore_1", "cogscore_2"), method = "bayes-lw", prob = T)
italy.pred
```


